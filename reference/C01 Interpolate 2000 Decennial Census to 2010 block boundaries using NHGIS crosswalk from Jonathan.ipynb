{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    \n",
    "Decide on how to create 2010 geom table from 2000.\n",
    "- We can create new geoid indices on 2000 tables to create a massive join\n",
    "- We can ingest entire 01-37 tables individually into RAM in python and interpolate in ram in place and write to\n",
    "     new 2000 tables\n",
    "- For either of the above we can decide to write all results into a single massive table, including new geoid column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array, csv, json, math, multiprocessing, numpy, os, random, re, shutil\n",
    "import shapely, shapely.wkb, struct, subprocess, sys, tempfile, threading, urllib2\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "exec_ipynb('timelapse-utilities.ipynb')\n",
    "\n",
    "set_default_psql_database('census2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosswalk:  download and document\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file('http://users.pop.umn.edu/~jps/NHGIS_block2000_to_block2010.zip', 'capture/NHGIS_block2000_to_block2010.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file('capture/NHGIS_block2000_to_block2010.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat capture/NHGIS_block2000_to_block2010/readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head capture/NHGIS_block2000_to_block2010/crosswalk_block2000_block2010_v002.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('SELECT * FROM crosswalk_block2000_block2010 '\n",
    "    \"WHERE geoid2010='010010201002007'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosswalk columns are:\n",
    "block_id_2000, block_id_2010, weight, parea\n",
    "We'll tentatively ignore the last.\n",
    "\n",
    "For a data column X, we want to compute:\n",
    "x2k(block_id_2010) = sum(x2k(block_id_2000)*weight(block_id_2000, block_id_2010)) for all block_id_2000 overlapping block_id_2010\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create crosswalk_block2000_block2010 database table\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('CREATE TABLE crosswalk_block2000_block2010 '\n",
    "    '(geoid2000 varchar, '\n",
    "    ' geoid2010 varchar, '\n",
    "    ' weight real, '\n",
    "    ' parea real)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = os.path.abspath('capture/NHGIS_block2000_to_block2010/crosswalk_block2000_block2010_v002.csv')\n",
    "psql(\"COPY crosswalk_block2000_block2010 \"\n",
    "     \"FROM '%s' DELIMITER ',' CSV;\" % full_path,\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"UPDATE crosswalk_block2000_block2010 SET \"\n",
    "     \"geoid2000 = right(geoid2000, 15), \"\n",
    "     \"geoid2010 = right(geoid2010, 15)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"CREATE INDEX ON crosswalk_block2000_block2010 (geoid2010)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"CREATE INDEX ON crosswalk_block2000_block2010 (geoid2000)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('\\d crosswalk_block2000_block2010', database='census2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create interpolated tables\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('\\d census2010_block_idxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code for creating a new interpolated table\n",
    "#DROP TABLE IF EXISTS {new_table};\n",
    "#DROP TABLE IF EXISTS {tmp_table};\n",
    "#CREATE TABLE {tmp_table} (blockidx2010, geoid2010, {columns})\n",
    "#AS SELECT MIN(blockidx2010), geoid2010, {sums}\n",
    "#FROM crosswalk_block2000_block2010\n",
    "#JOIN {old_table} USING (geoid2000)\n",
    "#JOIN census2010_block_idxs USING (geoid2010)\n",
    "#GROUP BY geoid2010;\n",
    "#CREATE UNIQUE INDEX ON {tmp_table} (blockidx2010);\n",
    "#CREATE UNIQUE INDEX ON {tmp_table} (geoid2010);\n",
    "#ALTER TABLE {tmp_table} RENAME TO {new_table};\n",
    "\n",
    "\n",
    "# census2010_block2010\n",
    "# census2000_block2010\n",
    "\n",
    "def interpolate_2000_to_2010(old_table, column, force=False):\n",
    "    # old_table: sf1_2000_block_p001\n",
    "    # census_table_name: p001\n",
    "    # SUM(weight * p001001)\n",
    "    dataset = 'census2000_block2010'\n",
    "    \n",
    "    cache_dir = 'columncache'\n",
    "    \n",
    "    # dataset, e.g. census2010 or census2000_int2010 or LEHD 2011\n",
    "    # table within dataset, e.g. P001 for census, HAC for LEHD\n",
    "    # column within table\n",
    "    # {cache_dir}/{dataset}/{census_table}-{column}.numpy\n",
    "    \n",
    "    dir_name = '{cache_dir}/{dataset}'.format(**locals())\n",
    "    !mkdir -p $dir_name\n",
    "    \n",
    "    cache_filename = '{dir_name}/{column}.numpy'.format(**locals())\n",
    "    if os.path.exists(cache_filename) and not force:\n",
    "        sys.stdout.write('{cache_filename} already exists\\n'.format(**locals()))\n",
    "        return\n",
    "\n",
    "    query = \"\"\"\n",
    "SELECT SUM(weight * {column})::REAL\n",
    "FROM crosswalk_block2000_block2010\n",
    "JOIN {old_table} USING (geoid2000)\n",
    "GROUP BY geoid2010\n",
    "ORDER BY geoid2010;\n",
    "\"\"\".format(**locals())\n",
    "\n",
    "    data = numpy.array([0] + [x[0] for x in query_psql(query)],\n",
    "                       dtype=numpy.float32)\n",
    "    \n",
    "    numpy_atomic_save(cache_filename, data)\n",
    "\n",
    "# interpolate_2000_to_2010('sf1_2000_block_p001', 'p001001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = SimpleThreadPoolExecutor(8)  # seems good for 64GB RAM earthserve2\n",
    "\n",
    "for table in sorted(get_table_names('sf1_2000_block_%')):\n",
    "    for column in get_census_column_names_from_view(table):\n",
    "        pool.submit(interpolate_2000_to_2010, table, column)\n",
    "\n",
    "pool.shutdown()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity-checking first interpolated table\n",
    "----------------------------------------\n",
    "The 2000 census includes Puerto Rico (FIPS 72), but the crosswalk doesn't, so checking that the overall populations match requires filtering out Puerto Rico from the original census count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('\\d sf1_2000_int2010_p001')\n",
    "psql('SELECT * FROM sf1_2000_int2010_p001 LIMIT 5;')\n",
    "psql('select SUM(p001001) from sf1_2000_int2010_p001;')\n",
    "psql('select SUM(p001001) from sf1_2000_block_p001;')\n",
    "psql(\"select SUM(p001001) from sf1_2000_block_p001 WHERE LEFT(geoid2000,2) != '72';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql('SELECT MAX(p001001) FROM sf1_2000_int2010_p001')\n",
    "psql('SELECT MAX(p001001) FROM sf1_2000_block_p001')\n",
    "psql('SELECT MAX(p001001) FROM sf1_2010_block_p001')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add geoid index to geo2000 table\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in hindsight, should have called this geoid2000\n",
    "psql(\"ALTER TABLE geo2000 ADD COLUMN geoid CHARACTER(15)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"UPDATE geo2000 SET geoid =\"\n",
    "     \" (state || county || tract || block)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"CREATE INDEX ON geo2000 (geoid)\",\n",
    "     database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psql(\"SELECT geoid FROM geo2000 WHERE sumlev='101' LIMIT 10\", database='census2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some 2000 'geoids'\n",
    "psql(\"SELECT state || county || tract || block FROM geo2000 WHERE sumlev='101' LIMIT 10\", database='census2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File identification (FILEID),state/US abbreviation (STUSAB),summary levels (SUMLEV),and the\n",
    "geographic component codes (GEOCOMP) are critical elements in identifying the geographic level\n",
    "for each record. The STUSAB field identifies the highest level of geography for the file. In the case\n",
    "of state file,it identifies the individual state. For SF 1 files,the following FILEID and STUSAB codes\n",
    "are used:\n",
    "SF 1 state and state equivalent files ‘uSF1’ ‘AL-WY’\n",
    "SF 1 advance national file ‘uSF1A’ ‘US’\n",
    "SF 1 final national file ‘uSF1F’ ‘US’"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
